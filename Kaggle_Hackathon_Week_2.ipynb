{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTG9DZCn618H",
        "outputId": "ab4bec14-d8f9-46a8-9f75-f067b04228a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:41<00:00,  8.36s/it]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "import lightgbm as lgb\n",
        "from tqdm import tqdm\n",
        "# Load data\n",
        "train = pd.read_csv('hacktrain.csv')\n",
        "test = pd.read_csv('hacktest.csv')\n",
        "\n",
        "# Fix column name case sensitivity\n",
        "ndvi_cols = [col for col in train.columns if '_N' in col]\n",
        "\n",
        "# Time-series preprocessing function\n",
        "def preprocess_ndvi(df, window=3):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Interpolation\n",
        "    df[ndvi_cols] = df[ndvi_cols].interpolate(axis=1, limit_direction='both')\n",
        "    # Fixed rolling window with transposition\n",
        "    df[ndvi_cols] = (df[ndvi_cols].T\n",
        "                       .rolling(window=window, min_periods=1)\n",
        "                       .mean()\n",
        "                       .T\n",
        "                       .values)\n",
        "    return df\n",
        "# Apply preprocessing\n",
        "train = preprocess_ndvi(train)\n",
        "test = preprocess_ndvi(test)\n",
        "# Advanced feature engineering\n",
        "def create_features(df):\n",
        "    # Basic stats\n",
        "    df['ndvi_mean'] = df[ndvi_cols].mean(axis=1)\n",
        "    df['ndvi_std'] = df[ndvi_cols].std(axis=1)\n",
        "    df['ndvi_max'] = df[ndvi_cols].max(axis=1)\n",
        "    df['ndvi_min'] = df[ndvi_cols].min(axis=1)\n",
        "    df['ndvi_amplitude'] = df['ndvi_max'] - df['ndvi_min']\n",
        "    # Temporal features\n",
        "    df['ndvi_median'] = df[ndvi_cols].median(axis=1)\n",
        "    df['ndvi_skew'] = df[ndvi_cols].skew(axis=1)\n",
        "    df['ndvi_kurtosis'] = df[ndvi_cols].kurtosis(axis=1)\n",
        "\n",
        "    # Slope (linear trend)\n",
        "    x = np.arange(len(ndvi_cols))\n",
        "    slopes = []\n",
        "    for _, row in df[ndvi_cols].iterrows():\n",
        "        coef = np.polyfit(x, row.values, 1)[0]\n",
        "        slopes.append(coef)\n",
        "    df['ndvi_slope'] = slopes\n",
        "\n",
        "    # Peak features\n",
        "    df['ndvi_peak_count'] = (df[ndvi_cols].diff(axis=1) > 0).sum(axis=1)\n",
        "    return df\n",
        "train = create_features(train)\n",
        "test = create_features(test)\n",
        "\n",
        "# Prepare data\n",
        "X = train.drop(columns=['ID', 'class', 'Unnamed: 0'], errors='ignore')\n",
        "y = train['class']\n",
        "X_test = test.drop(columns=['ID', 'Unnamed: 0'], errors='ignore')\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# LightGBM with Stratified K-Fold\n",
        "params = {\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': len(le.classes_),\n",
        "    'metric': 'multi_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'learning_rate': 0.05,\n",
        "    'num_leaves': 31,\n",
        "    'min_child_samples': 20,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'reg_alpha': 0.1,\n",
        "    'reg_lambda': 0.1,\n",
        "    'verbose': -1\n",
        "}\n",
        "n_folds = 5\n",
        "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "oof_preds = np.zeros((len(X), len(le.classes_)))\n",
        "test_preds = np.zeros((len(X_test), len(le.classes_)))\n",
        "# Import early stopping callback\n",
        "from lightgbm import early_stopping\n",
        "\n",
        "for fold, (train_idx, val_idx) in tqdm(enumerate(skf.split(X, y_encoded)), total=n_folds):\n",
        "  X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "  y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
        "  # Handle class imbalance\n",
        "  class_weights = dict(\n",
        "      zip(np.unique(y_train),\n",
        "      len(y_train) / (len(np.unique(y_train)) * np.bincount(y_train)))\n",
        "  )\n",
        "  sample_weights = np.array([class_weights[c] for c in y_train])\n",
        "  # Train model\n",
        "  model = lgb.LGBMClassifier(**params, n_estimators=2000)\n",
        "  model.fit(\n",
        "      X_train, y_train,\n",
        "      eval_set=[(X_val, y_val)],\n",
        "      eval_metric='multi_logloss',\n",
        "      # Use callbacks for early stopping\n",
        "      callbacks=[early_stopping(stopping_rounds=100, verbose=False)],\n",
        "      #early_stopping_rounds=100,\n",
        "      #verbose=False,\n",
        "      sample_weight=sample_weights\n",
        "  )\n",
        "  # Store predictions\n",
        "  oof_preds[val_idx] = model.predict_proba(X_val)\n",
        "  test_preds += model.predict_proba(X_test) / n_folds\n",
        "\n",
        "# Generate submission\n",
        "test_pred_labels = le.inverse_transform(test_preds.argmax(axis=1))\n",
        "submission = pd.DataFrame({'ID': test['ID'], 'class': test_pred_labels})\n",
        "submission.to_csv('improved_submission.csv', index=False)"
      ]
    }
  ]
}